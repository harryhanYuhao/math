{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATH10098: Numerical Linear Algebra - Computer lab week 5\n",
    "\n",
    "Below is an implementation of Algorithm GEPP. Have a look at the code to make sure you understand how it works before moving on to the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Implementation of Algorithm GEPP.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Using forwardsub and backsub from week 3.\n",
    "\n",
    "def FS(L, b):\n",
    "    # Find dimension of L\n",
    "    n = L.shape[0]\n",
    "    \n",
    "    # Initialise y to zero vector of correct length\n",
    "    y = np.zeros(n)\n",
    "    \n",
    "    # loop over elements of y, starting from first one\n",
    "    for j in range(n):\n",
    "        y[j] = (b[j] - L[j, :j] @ y[:j]) / L[j, j] # compute y_j\n",
    "        \n",
    "    return y\n",
    "\n",
    "def BS(U, y):\n",
    "    # Find dimension of U\n",
    "    n = U.shape[0]\n",
    "    \n",
    "    # Initialise x to zero vector of correct length\n",
    "    x = np.zeros(n)\n",
    "    \n",
    "    # loop over elements of x, starting from last one\n",
    "    for j in range(n-1, -1, -1):\n",
    "        x[j] = (y[j] - U[j, j+1:] @ x[j+1:]) / U[j, j] # compute x_j\n",
    "    \n",
    "    return x\n",
    "\n",
    "# New implementation of Algorithm LUPP\n",
    "\n",
    "def LUPP(A):\n",
    "    # Find dimension of A\n",
    "    n = A.shape[0]\n",
    "    \n",
    "    # Initialise matrices L=I, U=A, P=I\n",
    "    L = np.eye(n)\n",
    "    U = np.copy(A)\n",
    "    P = np.eye(n)\n",
    "    \n",
    "    for k in range(n - 1): # Loop over columns 1 to n-1\n",
    "        \n",
    "        # Find pivot i\n",
    "        i = np.argmax(np.abs(U[k:, k])) # Find position of maximum entry in required range\n",
    "        i += k # Shift index to start counting from row 1\n",
    "        \n",
    "        # Swap rows correspondingly\n",
    "        if i != k:\n",
    "            # swap rows in U, columns k to n\n",
    "            U[[k, i], k:] = U[[i, k], k:]\n",
    "            \n",
    "            # swap rows in L, columns 1 to k-1\n",
    "            L[[k, i], :k] = L[[i, k], :k]\n",
    "            \n",
    "            # swap rows in P\n",
    "            P[[k, i], :] = P[[i, k], :]\n",
    "        \n",
    "        # Loop over rows and make entries below\n",
    "        # diagonal in column k equal to 0\n",
    "        for j in range(k + 1, n): # loop over rows k+1 to n\n",
    "            L[j, k] = U[j, k] / U[k, k] # compute the multiplier l_jk\n",
    "            U[j, k:] = U[j, k:] - L[j, k] * U[k, k:] # subtract a multiple of row k from row j\n",
    "        \n",
    "    return L, U, P\n",
    "\n",
    "def GEPP(A, b):\n",
    "    L, U, P = LUPP(A) # find LU factorisation with permuation of A\n",
    "    y = FS(L, P @ b) # solve Ly=Pb using forward substitution\n",
    "    x = BS(U, y) # solve Ux=y using back substitution\n",
    "    return x\n",
    "\n",
    "# Test the functions\n",
    "A = np.array([[2, 1, 1], [4, 3, 3], [8, 7, 9]], dtype=float)\n",
    "b = np.array([4, 10, 24], dtype=float)\n",
    "x = GEPP(A, b)\n",
    "print('x = {}'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 (Easy)\n",
    "\n",
    "You may wish to use functions you have written in previous workshops and/or functions that were presented in lectures.\n",
    "\n",
    "For $n=50 \\times 2^k$ with $k=1, 2, \\dots, 5$:\n",
    "\n",
    "(i) Set up a random matrix `A` of dimension $n$.\n",
    "\n",
    "(ii) Create a vector `xsol` to represent a vector $x^{\\ast} \\in \\mathbb{R}^n$, all of whose entries are $1$.\n",
    "\n",
    "(iii) Compute the vector `b` such that $b = Ax^\\ast$.\n",
    "\n",
    "(iv) Use Algorithm GE to solve $Ax=b$, and store the solution in the variable `x1`. Take note of the elapsed time, as well as the $\\infty-$norm of the residual `A @ x1 - b` and the error `xsol - x1`. \n",
    "\n",
    "(v) Use Algorithm GEPP to solve $Ax=b$, and store the solution in the variable `x2`. Take note of the elapsed time, as well as the $\\infty-$norm of the residual `A @ x2 - b` and the error `xsol - x2`.\n",
    "\n",
    "How do the elapsed times of the two algorithms compare? Is this what you expected? Do you notice any trends with n?\n",
    "\n",
    "How do the norms of the residual and the error compare? Is this what you expected? Do you notice any trends with n?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def LU(A):\n",
    "    # Find dimension of A\n",
    "    n = A.shape[0]\n",
    "    \n",
    "    # Initialise L=I, U=A\n",
    "    L = np.eye(n) \n",
    "    U = np.copy(A)\n",
    "\n",
    "    for k in range(n - 1): # loop over columns 1 to n-1\n",
    "        for j in range(k + 1, n): # loop over rows k+1 to n\n",
    "            L[j, k] = U[j, k] / U[k ,k] # compute the multiplier l_jk\n",
    "            U[j, k:] = U[j, k:] - L[j, k] * U[k, k:] # subtract a multiple of row k from row j\n",
    "    \n",
    "    return L, U\n",
    "\n",
    "def GE(A, b):\n",
    "    L, U = LU(A)\n",
    "    y = FS(L, b)\n",
    "    x = BS(U, y)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.045772552490234375, 0.14466404914855957, 0.38098812103271484, 1.5008656978607178, 7.05253791809082]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Initialise lists to store times\n",
    "t_GEPP = []\n",
    "t_GE = []\n",
    "ge_norm_of_diff = []\n",
    "gepp_norm_of_diff = []\n",
    "\n",
    "for k in range (1,6):\n",
    "    # init matrices\n",
    "    A = np.random.rand(50*2**k, 50*2**k)\n",
    "    xsol = np.random.rand(50*2**k)\n",
    "    b = A @ xsol\n",
    "    #start time\n",
    "    start_time = time.time()\n",
    "    x = GE(A, b)\n",
    "    t_GE.append(time.time() - start_time)\n",
    "    # norm of diff\n",
    "    ge_norm_of_diff.append(np.linalg.norm(xsol - x))\n",
    "\n",
    "    # GEPP\n",
    "    start_time = time.time()\n",
    "    x = GEPP(A, b)\n",
    "    t_GEPP.append(time.time() - start_time)\n",
    "    # norm of diff\n",
    "    gepp_norm_of_diff.append(np.linalg.norm(xsol - x))\n",
    "\n",
    "\n",
    "print(t_GE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.852067485640262e-12, 3.650141864189309e-11, 1.8517226000589403e-10, 1.6550859901134115e-08, 4.745268698433236e-09]\n",
      "[1.4385651643615627e-13, 2.7189764757014477e-12, 3.2048356085653496e-12, 2.674651077530405e-11, 4.0998939421168116e-11]\n"
     ]
    }
   ],
   "source": [
    "print(ge_norm_of_diff)\n",
    "print(gepp_norm_of_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 (Standard)\n",
    "\n",
    "Consider the system of linear equations\n",
    "$$\n",
    "\\mathbf A \\mathbf x = \\mathbf b,\n",
    "$$\n",
    "where $\\mathbf A \\in \\mathbb R^{n \\times n}$ is invertible and $\\mathbf b \\in \\mathbb R^n$.\n",
    "\n",
    "Cramer's rule states that the solution is given by\n",
    "$$\n",
    "x_i = \\frac{det (\\mathbf {A_i})}{det(\\mathbf A)}, \\qquad i=1, \\dots, n, \n",
    "$$\n",
    "where $\\mathbf {A_i} \\in \\mathbb R^{n \\times n}$ is the matrix $\\mathbf A$ with the $i$th column replaced by $\\mathbf b$ and $det$ denotes the determinant.\n",
    "\n",
    "(i) Write a function *det* that uses the LU factorisation of $\\mathbf A$ to compute $det(\\mathbf A)$. Test your code on the example at the bottom of the code cell (the correct answer is 2).\n",
    "\n",
    "Have you thought about computational efficiency in your code? Ask your tutor to have a look.\n",
    "\n",
    "*Python's built in determinant function np.linalg.det is in fact based on an LU factorisation with partial pivoting.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def det(A):  \n",
    "    L, U = LU(A)\n",
    "    d = 1\n",
    "    for i in range(L.shape[0]):\n",
    "        d *= L[i][i] * U[i][i]\n",
    "    return d\n",
    "\n",
    "\n",
    "# Testing the function on the given example, the correct answer is 2\n",
    "A = np.array([[2, 1, 1], [4, 3, 3], [6, 7, 8]], dtype=float)\n",
    "d = det(A)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii) Write a function *solve_Cramer* that computes the solution $\\bf x$ using Cramer's rule. You can use your function *det* from part (i), or the built-in Python routine np.linalg.det.\n",
    "\n",
    "Have you thought about computational efficiency in your code? Ask your tutor to have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 1.],\n",
       "       [1., 2., 1.],\n",
       "       [1., 2., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.ones((3,3))\n",
    "b = 2*np.ones(3)\n",
    "A[:,1]=b\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -2.  4.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def solve_Cramer(A,b):\n",
    "    aLen = A.shape[0]\n",
    "    x = np.empty(aLen)\n",
    "    for i in range(aLen):\n",
    "        A_i = A.copy()\n",
    "        A_i[:,i] = b\n",
    "        x[i] = det(A_i)/det(A)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Testing the function on the given example, the correct answer is [1, -2, 4]\n",
    "A = np.array([[2, 1, 1], [4, 3, 3], [6,7,8]], dtype=float)\n",
    "b = np.array([4,10,24], dtype=float) \n",
    "x = solve_Cramer(A,b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iii) How does Cramer's rule from part (ii) compare to the built-in Python solver np.linalg.solve in terms of computational time and accuracy of the computed solution? Test the two methods on matrices of varying size $n$ between 10 and 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 (Standard, open-ended)\n",
    "\n",
    "The accuracy of the computed solution $x$ of the system $Ax=b$ can sometimes be improved by a process called iterative refinement:\n",
    "\n",
    "1. Solve $Ax = b$ with GE\n",
    "2. Compute the residual $r = b - Ax$\n",
    "3. Solve $Ad = r$\n",
    "4. Update $x \\leftarrow x + d$.\n",
    "\n",
    "Steps 2--4 are repeated until convergence to a more accurate solution. At each iteration, since the matrices $L$, $U$ have already been computed when solving $Ax=b$, they can be used to solve $Ad=r$ at a cost of $O(n^2)$.\n",
    "\n",
    "Write a function `GE_ref`, based on your function `GE`, to compute a solution to $Ax=b$ using GE with iterative refinement. Investigate the performance of `GE_ref` compared to that of `GE` and `GEPP`; you may wish to use test cases from Exercise 1 (investigating different $n$) and the Week 3.2 Jupyter notebook (investigating different condition numbers $\\kappa_2(A)$).\n",
    "\n",
    "Further improvements on the iterative refinement method are described in [this paper](https://doi.org/10.1137/17M1122918) -- you may wish to implement/investigate some of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 (Difficult)\n",
    "\n",
    "The matrix $A \\in \\mathbb{R}^{n\\times n}$ is called *tridiagonal* if $a_{ij}=0$ for $|i - j|>1$. Tridiagonal matrices appear naturally in many applications, such as the numerical solution of ordinary differential equations. Due to their simple structure, tridiagonal matrices have some special properties and specialised algorithms.\n",
    "\n",
    "For a tridiagonal matrix $A$, the LU factors $L$ and $U$ are also tridiagonal:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "a_{11} & a_{12} & & \\\\\n",
    "a_{21} & a_{22} & \\ddots &   \\\\\n",
    "& \\ddots & \\ddots  & a_{n-1,n} \\\\\n",
    "& & a_{n,n-1}& a_{nn}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & & \\\\ l_{21} & 1 & \\ddots &   \\\\\n",
    "& \\ddots & \\ddots  & 0 \\\\\n",
    "& & l_{n,n-1}& 1\n",
    "\\end{bmatrix}\n",
    "\\;\n",
    "\\begin{bmatrix}\n",
    "u_{11} & u_{12} & & \\\\\n",
    "0 & u_{22} & \\ddots &   \\\\\n",
    "& \\ddots & \\ddots  & u_{n-1,n} \\\\\n",
    "& & 0& u_{nn}\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "(i) Explain why algorithm LU is not efficient for tridiagonal matrices, i.e. explain why it performs many unnecessary arithmetic operations.\n",
    "\n",
    "(ii) Write down pseudo-code for an Algorithm LU-TRI, an efficient algorithm for computing the LU factorisation of a tridiagonal matrix. *Hint: Multiply the above matrices $L$ and $U$ to find equations for $u_{ii}$, $u_{i, i+1}$, and $l_{i, i-1}$ involving the entries of A. Start by computing $u_{11}$.*\n",
    "\n",
    "(iii) Write a function `LU_tri` which implements your LU-TRI algorithm.\n",
    "\n",
    "(iv) How does the computational time of Algorithm LU-TRI seem to grow with $n$? Is this what you would expect? You may wish to verify your findings numerically by setting up tridiagonal matrices using the command np.diag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# add code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
