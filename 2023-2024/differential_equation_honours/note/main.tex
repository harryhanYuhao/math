% available style: report
\documentclass[12pt]{article}

\input{preamble}

\title{Differential Equation Note}
\author{Harry Han}
\date{\today}

\begin{document}

\section{Theory Of Differential Equations}

\begin{definition}[Classification of Differential Equations] 
	Differential equations involves in relations of functions and their derivatives.
	We usually use $t$ as independent variable with physical meaning of time.

	If only ordinary derivatives (the function depends only in one variable) are involved, the equation is called an \textbf{ordinary differential equation} (ODE).
	If partial derivatives are involved, the equation is called a \textbf{partial differential equation} (PDE).

	\textbf{Order} of a differential equation is the order of the highest derivative.
	A $n$th order ODE can be written as $F(t, x, x'', \cdots, x^{(n)}) = 0$. If $F$ is a linear function, we call this a linear ODE.

	A linear ODE is \textbf{homogeneous} if it can be written as $a_{n}x^{(n)} + a_{n-1}x^{(n-1)} + \cdots + a_{1}x' + a_{0}x = 0$ for constants $a_i$.
\end{definition}

\begin{definition}[Initial Value Problem]
	%TODO:
\end{definition}

\begin{theorem}[Solutions To linear Homogeneous ODE]
	Solutions to $n$th degree Linear homogeneous ODE of one function forms a vector space of $n$ dimension.

	I.e., with ODE $a_{n}x^{(n)} + a_{n-1}x^{(n-1)} + \cdots + a_{1}x' + a_{0}x = 0$, the set of solutions forms a vector space of dimension $n$.
\end{theorem}

\begin{theorem}[Existance And Uniqueness Theore for Initial Value Problem]
	Assuming we have the system of ODE 
	\begin{equation}
	\begin{split}
	x_1' &= f_1(t, x_1, x_2, \cdots, x_n) \\
	x_2' &= f_2(t, x_1, x_2, \cdots, x_n) \\
	&\cdots \\
	x_n' &= f_n(t, x_1, x_2, \cdots, x_n) \\
	\end{split}
	\end{equation}
	with initial condition $x_i(t_0) = x_{i0}$ for $i = 1, 2, \cdots, n$. 

	If $f_i$ and $\partial_{x_j}f_i$ for all applicable $i, j$ are continuous in a region $R$ containing $(t_0, x_{10}, x_{20}, \cdots, x_{n0})$, then there exists a unique solution $x_i = x_i(t)$ defined on an interval $I$ containing $t_0$.
\end{theorem}

\section{Easy Differential Equations}

\begin{theorem}
	The equation $\frac{dy}{dt} + p(t)y = g(t)$ is solved by $y(t) = \frac{1}{\mu(t)} (\int \mu(t)g(t)dt+C)$ where $\mu(t) = \exp{\int p(t)dt}$.

\end{theorem}


\section{Linear ODE}

\begin{theorem}[System of Homogeneous Linear ODE]
	To find solution to the linear homogeneous system with constant coefficients $\bm{x}' = \bm{A}\bm{x}$ is to find the eiganvalue and eiganvector of $\bm{A}$.
	If there is eiganvectors forming a basis of $\mathbb{R}^n$, then the solution is
	$$ \bm{x} = \sum_{i=1}^{n} c_i \bm{\xi}_i e^{\lambda_i t} $$

	For $n=2$.
	If there is one repeated eiganvalue $\rho$ corresponding the the vector $\xi$. The first solution is $\bm{x}_1 = \bm{\xi} e^{\rho t}$, and the second solution is $\bm{x}_2 = \bm{\xi} t e^{\rho t} + \bm{\eta} e^{\rho t}$, where $(\bm{A} - \rho \bm{I}) \bm{\eta} = \bm{\xi}$
\end{theorem}

\begin{definition}[Fundamental Matrix]
	$\bm{\psi}$ is fundamental matrix of $\bm{x}' = \bm{A}\bm{x}$ if each column of it is a solution to the system and $\det{\bm{\psi}} \neq 0$. (The space of its solutions)
\end{definition}

\begin{theorem}[Non-homogeneous linear ODE problem]
	Consider Non-homogeneous problem $\bm{x}' = \bm{Ax} + \bm{g}$

\textbf{Diagonalisation}
We can diagonlise $\bm{A} = \bm{T}^{-1}\bm{DT}$. Let $\bm{x} = \bm{Ty}$ and solve $\bm{y}' = \bm{Dy} + \bm{T}^{-1}\bm{g}$, then $\bm{x} = \bm{T} \bm{y}$ is the solution.

\textbf{Variation of Parameters}
Let $\bm{\psi}$ be the fundamental matrix of $\bm{x}' = \bm{Ax}$. The particular solution is $\bm{\psi}\int \bm{\psi}^{-1}\bm{g} dt$.
\end{theorem}

\section{Laplace Transform}

\begin{definition}[Laplace Transform]
	\begin{equation}
		\L{f(t)} = \int_{0}^{\infty} e^{-st} f(t) dt
	\end{equation}
\end{definition}

\begin{theorem}[Tables of Laplace Transform]
	\ 
\begin{enumerate}
	\item $\L{f^{(n)}(t)} = s^n \L{f(t)} - s^{n-1}f(0) - s^{n-2}f'(0) - \cdots - f^{(n-1)}(0)$
	\item $\L{u_{c}(t)} = \frac{e^{-cs}}{s}$
	\item $\L{u_c(t)f(t-c)} = e^{-cs} \L{f}$, domain unchanged. $(u_c(t) = t, t<c, 1$ otherwise)
	\item $\L{e^{ct}f(t)} = \L{f}(s-c)$,$s-c > a$, if $\L{f}$ is defined for $s>a$
	\item $\L{\delta(t-a)} = e^{-sa}$
	\item $\L{t^nf(t)} = (-1)^n \frac{d^n}{ds^n} \L{f}(s)$
	\item $\L{f(ct)} = \frac{1}{c}F(\frac{s}{c})$
	\item $\L{1} = \frac{1}{s}$
	\item $\L{e^{at}} = \frac{1}{s-a}$ for $s>a$
	\item $\L{\sin{at}} = \frac{a}{s^2+a^2}$ for $s>0$
	\item $\L{\cos{at}} = \frac{s}{s^2+a^2}$ for $s>0$
	\item $\L{e^{at}\sin{bt}} = \frac{b}{(s-a)^2+b^2}$ for $s>a$
	\item $\L{e^{at}\cos{bt}} = \frac{s-a}{(s-a)^2+b^2}$ for $s>a$
	\item $\L{t^n} = \frac{n!}{s^{n+1}}$ for $s>0$
	\item $\L{\sinh{at}} = \frac{a}{s^2-a^2}$ for $s>|a|$
	\item $\L{\cosh{at}} = \frac{s}{s^2-a^2}$ for $s>|a|$
	\item $\L{t^n e^{at}} = \frac{n!}{(s-a)^{n+1}}$ for $s>a$
\end{enumerate}	
\end{theorem}

\begin{theorem}[Convolution Theorem]
	$$ f*g(t) =  \int_{0}^{t} f(t-\tau)g(\tau) d\tau$$
	\begin{enumerate}
		\item $\L{f*g} = \L{f} \L{g}$
		\item $f*g = g*f$
		\item $f*(g*h) = (f*g)*h$
		\item $f*(g+h) = f*g + f*h$
	\end{enumerate}
\end{theorem}

\section{Autonumous System}
Considering a system of ODE: $\frac{dx}{dt} = F(x,y), \frac{dy}{dt} = G(x,y)$. $F, G$ are independent of $t$. This system is \textbf{autonomous}.

\begin{definition}[Critical Point]
	$(x_0, y_0)$ is a critical point if $F(x_0, y_0) = G(x_0, y_0) = 0$.
\end{definition}

The nature of critical is easy to determine for linear system. 

\begin{definition}[Almost Linear System]
	Consider autonomous system $\bm{x}' = \bm{A}\bm{x} + \bm{g}(\bm{x})$.  
	If $\bm{0}$ is a critical point, and $\frac{||\bm{g}||}{||\bm{x}||} \rightarrow \bm{0}$ as $\bm{x} \rightarrow \bm{0}$, this is an almost linear system.
	Significantly, if $F, G$ are twice differentiable. The system is almost linear, and is approximated by
	$\frac{d}{dt} \bm{u} = \begin{bmatrix} F_x & F_y \\ G_x & G_y \end{bmatrix} \bm{u} $, where $\hat{\bm{x}}$ is a critical point, $F_x = F_x(\hat{\bm{x}}), \cdots$, $\bm{u} = \bm{x} - \hat{\bm{x}}$.
	The stability of $\hat{\bm{x}}$ for the almost linear system is the same as linear system, except when the linear system has purly imaginary eiganvalues or equal real eiganvalues.
\end{definition}

\begin{theorem}[Lyapunov]
	For a linear system $x' = F(x,y)$, $y' = G(x,y)$. We can find a Lyapunov function $V(x(t), y(t))$ such that $V$ is positive definite and $V' = \frac{dV}{dx}\frac{dx}{dt} + \frac{dV}{dy} \frac{dy}{dt} $ is negative definite in a domain containing $(0,0)$, then $(0,0)$ is asymptotic stable critical point. IF $V'$ semi negative definite, $(0,0)$ is stable. 

	If For all interval containing $(0,0)$ there is a point such that $V$ is positive, while $V'$ is positive definite in a domain containing $(0,0)$, $\bm{0}$ is unstable.
\end{theorem}

\begin{theorem}
If $F,G$ has continuous partial derivative is domain $D$, a close trajectory must contain a critical point that is not a saddle point.
\end{theorem}

\begin{theorem}
If function $F, G$ has continuous first partial derivative in simply connected domain $D$. If $F_x + G_y$ has the same sign in $D$, then there is no close trajectory in $D$.
\end{theorem}

\begin{theorem}[Poincare-Bendixson]
	Let $F,G$ have continuous first partial derivative. Let $D$ be a closed set containing no critical point. If there exists a trajectory in $D$ for all $t>t_0$, there must be a closed trajectory (periodic solution) in $D$.
\end{theorem}

\section{Fourier Series}
\begin{theorem}[Fourier Convergence Theorem]
	Suppose $f$ and $f'$ are piecewise continuous on interval $-L < x < L$, while $f$ is periodic with period $2L$. Then,

	$f(x) = \frac{a_0}{2} + \sum_{n=1}^{\infty} (a_n \cos{\frac{n\pi x}{L}} + b_n \sin{\frac{n\pi x}{L}})$,

	where $a_n = \frac{1}{L} \int_{-L}^{L} f(x) \cos{\frac{n\pi x}{L}} dx$, $b_n = \frac{1}{L} \int_{-L}^{L} f(x) \sin{\frac{n\pi x}{L}} dx$.
\end{theorem}

\section{Sturm Liouville Theory}

\begin{theorem}[Homogeneous Sturm Liouville Problem] 
	\begin{equation}
		[p(x)y']' - q(x)y + \lambda r(x) y = 0
	\end{equation}
	With Boundary Conditions $\alpha_1 y(0) + \alpha_2 y'(0) = 0, \beta_1 y(1) = \beta_2 y'(1) = 0$.
	Which can be written as, with $L(y) = -[p(x)y']' + q(x)y$:
	$$L[y] = \lambda r(x)y$$

	For $u,v$ satisfying the boundary conditions, we have: $(u, L(v)) = (L(u), v)$.

	$\lambda$ is the eigenvalues, $\phi$ are the eigenfunctions.

	A function, $f$, can be expanded as $f(x) = \sum_{n=1}^{\infty} c_n \phi_n(x)$, where $c_n = \int_0^1 r(x)f(x)\phi_m(x)dx$
\end{theorem}

\begin{theorem}[Non-homogeneous Sturm Liouville Problem]
	\begin{equation}
		[p(x)y']' - q(x)y +  \mu r(x) y + f(x)= 0 \iff L[y] = \mu r(x) y + f(x)
	\end{equation}
	Have solution $y = \phi(x) = \sum^{\infty}_{n=1} \frac{c_n}{\lambda_n - \mu}$.
	Where $\lambda, \phi$ are eigenvalues and function to the problem $L[y] = \lambda r(x) y$. $c_n = \int_0^1 r(x)f(x)\phi_n(x)dx$
\end{theorem}



\end{document}
